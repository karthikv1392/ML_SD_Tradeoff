{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc1dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import numpy as np\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eec2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-06-22 12:00:00')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DAY_MS = 24*60*60*1000 # a day length in ms\n",
    "\n",
    "def tf_hour_mapper(ts_init, ts_end, ts_occurr_str, days_offset):\n",
    "    \"\"\"Convert the given timestamp into a 24 hour format one, on the basis of the\n",
    "       timestamp interval given\"\"\"\n",
    "    \n",
    "    ts_occurr = pd.to_datetime(ts_occurr_str)\n",
    "    \n",
    "    today = date.today().strftime('%Y-%m-%d')\n",
    "    \n",
    "    if ts_occurr == ts_init:\n",
    "        # TODO: return 00:00:00\n",
    "        return pd.to_datetime(f\"{today} 00:00:00.000000\") - pd.Timedelta(days=days_offset)\n",
    "    if ts_occurr == ts_end:\n",
    "        # TODO: return 23:59:59\n",
    "        return pd.to_datetime(f\"{today} 23:59:59.999999\") - pd.Timedelta(days=days_offset)\n",
    "    \n",
    "    delta = ts_end - ts_init\n",
    "    delta_ms = delta.total_seconds() * 1000\n",
    "    \n",
    "    occurr_delta = ts_occurr - ts_init\n",
    "    occurr_delta_ms = occurr_delta.total_seconds() * 1000\n",
    "    \n",
    "    # day in ms : ms of simulated day = x : ms of ts_occurr from init\n",
    "    \n",
    "    x = DAY_MS * occurr_delta_ms / delta_ms\n",
    "    seconds = (x / 1000) % 60;\n",
    "    minutes = int((x / (1000*60)) % 60);\n",
    "    hours   = int((x / (1000*60*60)) % 24);\n",
    "    \n",
    "    # TODO: return timestamp with the calculated metrics\n",
    "    ts_out_str = \"{} {}:{}:{:.6f}\".format(today, hours, minutes, seconds)\n",
    "    ts_out = pd.to_datetime(ts_out_str) \n",
    "    \n",
    "    ts_out = ts_out - pd.Timedelta(days=days_offset)\n",
    "    return ts_out\n",
    "\n",
    "\n",
    "\n",
    "x = tf_hour_mapper(pd.to_datetime(\"2022-05-19 13:34:18.951007\"),\n",
    "                   pd.to_datetime(\"2022-05-19 13:36:18.951007\"),\n",
    "                                  \"2022-05-19 13:35:18.951007\", 5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53dcc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_workload_csv(filepath) -> pd.DataFrame:\n",
    "    \"\"\"Read and clean csv workload from filepath\"\"\"\n",
    "    file_exists = os.path.exists(filepath)\n",
    "    \n",
    "    if not file_exists:\n",
    "        raise FileNotFoundError\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    # drop id column\n",
    "    df = df.iloc[: , 2:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da79cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_store_workload(folder, filename, days_offset):\n",
    "    \"\"\"Given a workload csv filepath and a days_offset, this function convert timestamps in 24 hours format,\n",
    "       taking into account the days_offset\"\"\"\n",
    "    \n",
    "    path_to_csv = f\"{folder}/{filename}\"\n",
    "    \n",
    "    # create a folder for the simulated workloads if not exists\n",
    "    sim_folder = f\"{folder}/sim\"\n",
    "    is_exist = os.path.exists(sim_folder)\n",
    "\n",
    "    if not is_exist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(sim_folder)\n",
    "        display(f\"Folder {sim_folder} created\")\n",
    "        \n",
    "    display(f\"Converting {filename} with day offset of {days_offset}\")\n",
    "    df = read_workload_csv(path_to_csv)\n",
    "    \n",
    "    df = df.sort_values(by=['timestamp'])\n",
    "    \n",
    "    # identify start and end timestamps\n",
    "    ts_init = df['timestamp'].min() # init -> 00:00:00\n",
    "\n",
    "    ts_end = df['timestamp'].max() # end -> 23:59:59\n",
    "\n",
    "    ts_init = pd.to_datetime(ts_init) # str -> pandas.Timestamp\n",
    "    ts_end = pd.to_datetime(ts_end) \n",
    "    \n",
    "    # CONVERT TIMESTAMPS TO 24 HOUR FORMAT\n",
    "    df['sim_timestamp']=df.apply(lambda row: tf_hour_mapper(ts_init, ts_end, row['timestamp'], days_offset), axis=1)\n",
    "    \n",
    "    # drop old ts column\n",
    "    df.drop('timestamp', axis=1, inplace=True)\n",
    "    \n",
    "    # re-ordering columns\n",
    "    timestamp_sim_col = df.pop('sim_timestamp')\n",
    "    df.insert(0, 'timestamp', timestamp_sim_col)\n",
    "    \n",
    "    # store\n",
    "    df.to_csv(f'{sim_folder}/{filename[:-4]}_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "418299fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Converting workload_101.csv with day offset of 14'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_102.csv with day offset of 13'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_103.csv with day offset of 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_104.csv with day offset of 11'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_105.csv with day offset of 10'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_106.csv with day offset of 9'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_107.csv with day offset of 8'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_108.csv with day offset of 7'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_109.csv with day offset of 6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_110.csv with day offset of 5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_111.csv with day offset of 4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_112.csv with day offset of 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_113.csv with day offset of 2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Converting workload_114.csv with day offset of 1'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = np.arange(101, 114 +1)\n",
    "\n",
    "for i in ids:\n",
    "\n",
    "    day_offset = ids[-1] - i + 1\n",
    "    folder = \"../postgres/data/rr_week/rt\"\n",
    "    filename = f\"workload_{i}.csv\"\n",
    "    \n",
    "    is_exist = os.path.exists(folder)\n",
    "\n",
    "    if not is_exist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(folder)\n",
    "        display(f\"Folder {folder} created\")\n",
    "    \n",
    "    convert_and_store_workload(folder, filename, day_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc70458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
