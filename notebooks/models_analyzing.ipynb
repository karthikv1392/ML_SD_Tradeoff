{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "364e561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import json\n",
    "from time import time\n",
    "from os import listdir\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sess = None\n",
    "graph = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86db2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(BASE_ROOT_FILE, prediction_strategy):\n",
    "    global sess\n",
    "    global graph\n",
    "    sess = tf.Session()\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    print(\"loading file\")\n",
    "    dir_path = BASE_ROOT_FILE + '/' + prediction_strategy\n",
    "\n",
    "    if os.path.exists(dir_path):\n",
    "        start = time()\n",
    "        # init files\n",
    "        files[prediction_strategy] = {}\n",
    "\n",
    "        # load model\n",
    "        files_name = fnmatch.filter(listdir(dir_path), '*.sav')\n",
    "        for file_name in files_name:\n",
    "            set_session(sess)\n",
    "            full_name = dir_path + '/' + file_name\n",
    "            files[prediction_strategy, file_name] = joblib.load(full_name)\n",
    "\n",
    "        # load input files\n",
    "        files_name = fnmatch.filter(listdir(dir_path), '*.json')\n",
    "        for file_name in files_name:\n",
    "            full_name = dir_path + '/' + file_name\n",
    "            files[prediction_strategy, file_name] = json.loads(open(full_name).read())\n",
    "\n",
    "        end = time()\n",
    "        print(\"Model loaded in \" + str(end - start) + \" ms for strategy \" + prediction_strategy)\n",
    "    print(\"file loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "631ab69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 11:44:56.294140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-24 11:44:56.294168: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-24 11:44:56.294189: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (steph-R5): /proc/driver/nvidia/version does not exist\n",
      "2022-05-24 11:44:56.294672: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "    ## read files\n",
    "    model = joblib.load('carts.model.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5185b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd16fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# summarize history for accuracy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cc3255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
